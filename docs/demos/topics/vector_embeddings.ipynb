{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Embeddings in FireProx\n",
    "\n",
    "This notebook demonstrates how to work with vector embeddings in FireProx using the native `google.cloud.firestore_v1.vector.Vector` class.\n",
    "\n",
    "## Important Limitations\n",
    "\n",
    "**Firestore Emulator Does NOT Support Vector Embeddings**\n",
    "\n",
    "- Vector embeddings are a production-only feature\n",
    "- The Firestore emulator will reject any operations involving vectors\n",
    "- All examples in this notebook require a real Firestore instance\n",
    "- See [GitHub Issue #7216](https://github.com/firebase/firebase-tools/issues/7216)\n",
    "\n",
    "**Vector Constraints**:\n",
    "- Maximum 2048 dimensions per vector\n",
    "- Vectors cannot be nested inside arrays or maps\n",
    "- Vectors must be at the top level of a document field\n",
    "\n",
    "## What are Vector Embeddings?\n",
    "\n",
    "Vector embeddings are numerical representations of data (text, images, etc.) that capture semantic meaning. They enable:\n",
    "- Semantic search (find similar documents)\n",
    "- Clustering and classification\n",
    "- Recommendation systems\n",
    "- Question answering\n",
    "\n",
    "FireProx uses the native Firestore `Vector` type directly for seamless integration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "**Note**: These examples will fail with the emulator. You must use a real Firestore project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import firestore\n",
    "from google.cloud.firestore_v1.vector import Vector\n",
    "from google.cloud.firestore_v1.base_vector_query import DistanceMeasure\n",
    "\n",
    "from fire_prox import AsyncFireProx, FireProx\n",
    "\n",
    "# Check if running in CI environment\n",
    "if os.environ.get('NOTEBOOK_CI'):\n",
    "    print(\"⚠️  Running in CI - skipping vector examples (requires production Firestore)\")\n",
    "    import sys\n",
    "    sys.exit(0)\n",
    "\n",
    "# Initialize clients (PRODUCTION ONLY - will not work with emulator)\n",
    "project_id = 'your-project-id'  # Replace with your actual project ID\n",
    "\n",
    "# Synchronous client\n",
    "sync_client = firestore.Client(project=project_id)\n",
    "db = FireProx(sync_client)\n",
    "\n",
    "# Asynchronous client\n",
    "async_client = firestore.AsyncClient(project=project_id)\n",
    "async_db = AsyncFireProx(async_client)\n",
    "\n",
    "print(\"✓ Connected to production Firestore\")\n",
    "print(\"⚠️  Remember: Vector embeddings DO NOT work with the emulator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 1: Creating and Storing Vectors (Sync)\n",
    "\n",
    "Create a native `Vector` from a list of floats and store it in a document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a collection for documents with embeddings\n",
    "documents = db.collection('semantic_documents')\n",
    "\n",
    "# Create a simple 3-dimensional embedding using native Vector\n",
    "doc1 = documents.new()\n",
    "doc1.title = \"Introduction to Machine Learning\"\n",
    "doc1.content = \"Machine learning is a subset of artificial intelligence...\"\n",
    "doc1.embedding = Vector([0.12, 0.45, 0.78])  # Native Vector instance\n",
    "\n",
    "# Save to Firestore\n",
    "doc1.save(doc_id='ml_intro')\n",
    "\n",
    "print(f\"✓ Saved document with {len(doc1.embedding.to_map_value()['value'])} dimensions\")\n",
    "print(f\"  Title: {doc1.title}\")\n",
    "print(f\"  Embedding type: {type(doc1.embedding).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 2: Reading Vectors from Firestore (Sync)\n",
    "\n",
    "FireProx automatically preserves native Firestore Vectors when reading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the document back\n",
    "retrieved = db.doc('semantic_documents/ml_intro')\n",
    "retrieved.fetch()\n",
    "\n",
    "# Access the vector - stays as native Vector\n",
    "print(f\"Document: {retrieved.title}\")\n",
    "print(f\"Embedding type: {type(retrieved.embedding).__name__}\")\n",
    "print(f\"Vector: {retrieved.embedding}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 3: Working with Higher-Dimensional Embeddings\n",
    "\n",
    "Real-world embeddings typically have many more dimensions (e.g., 384, 768, 1536 dimensions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Create a document with a realistic 384-dimensional embedding\n",
    "# (typical for models like sentence-transformers/all-MiniLM-L6-v2)\n",
    "doc2 = documents.new()\n",
    "doc2.title = \"Deep Learning Fundamentals\"\n",
    "doc2.content = \"Deep learning uses neural networks with multiple layers...\"\n",
    "\n",
    "# Generate a random 384-dimensional embedding (in practice, use a real model)\n",
    "embedding_384d = [random.random() for _ in range(384)]\n",
    "doc2.embedding = Vector(embedding_384d)\n",
    "\n",
    "doc2.save(doc_id='dl_fundamentals')\n",
    "\n",
    "dimension_count = len(doc2.embedding.to_map_value()['value'])\n",
    "print(f\"✓ Saved document with {dimension_count}-dimensional embedding\")\n",
    "values = doc2.embedding.to_map_value()['value']\n",
    "print(f\"  First 5 dimensions: {values[:5]}\")\n",
    "print(f\"  Last 5 dimensions: {values[-5:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 4: Dimension Validation\n",
    "\n",
    "Firestore enforces a maximum dimension limit of 2048."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DIMENSIONS = 2048\n",
    "\n",
    "print(f\"Firestore maximum dimensions: {MAX_DIMENSIONS}\")\n",
    "\n",
    "# This works - exactly at the limit\n",
    "max_vector = Vector([0.1] * MAX_DIMENSIONS)\n",
    "print(f\"✓ Created vector with {len(max_vector.to_map_value()['value'])} dimensions (max allowed)\")\n",
    "\n",
    "# This will fail when you try to save - exceeds the limit\n",
    "try:\n",
    "    too_large = Vector([0.1] * (MAX_DIMENSIONS + 1))\n",
    "    doc_test = documents.new()\n",
    "    doc_test.embedding = too_large\n",
    "    # doc_test.save()  # This would fail\n",
    "    print(f\"\\n⚠️  Created vector with {len(too_large.to_map_value()['value'])} dimensions\")\n",
    "    print(\"   (This will fail when you try to save to Firestore!)\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n✗ Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 5: Async Operations with Vectors\n",
    "\n",
    "Vectors work seamlessly with the async API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Async version - store and retrieve vectors\n",
    "async_documents = async_db.collection('semantic_documents')\n",
    "\n",
    "# Create and save\n",
    "async_doc = async_documents.new()\n",
    "async_doc.title = \"Neural Network Architectures\"\n",
    "async_doc.content = \"Neural networks consist of interconnected layers...\"\n",
    "async_doc.embedding = Vector([0.23, 0.56, 0.89])\n",
    "\n",
    "await async_doc.save(doc_id='nn_architectures')\n",
    "\n",
    "dimension_count = len(async_doc.embedding.to_map_value()['value'])\n",
    "print(f\"✓ Saved async document with {dimension_count}D embedding\")\n",
    "\n",
    "# Read back\n",
    "async_retrieved = async_db.doc('semantic_documents/nn_architectures')\n",
    "await async_retrieved.fetch()\n",
    "\n",
    "print(f\"\\nRetrieved: {async_retrieved.title}\")\n",
    "print(f\"Embedding: {async_retrieved.embedding}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 6: Real-World Example - Text Embeddings\n",
    "\n",
    "Simulate generating embeddings from text using a hypothetical embedding model.\n",
    "\n",
    "**Note**: This example shows the pattern. In production, you would use a real embedding model like:\n",
    "- OpenAI's `text-embedding-ada-002` (1536 dimensions)\n",
    "- Sentence Transformers (384-768 dimensions)\n",
    "- Google's Vertex AI embeddings (768 dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_embedding(text: str, dimensions: int = 384) -> list:\n",
    "    \"\"\"\n",
    "    Simulate an embedding model (in production, use a real model).\n",
    "    \n",
    "    Real examples:\n",
    "    - openai.embeddings.create(input=text, model=\"text-embedding-ada-002\")\n",
    "    - sentence_transformers.SentenceTransformer('all-MiniLM-L6-v2').encode(text)\n",
    "    - vertexai.TextEmbeddingModel.from_pretrained('textembedding-gecko').get_embeddings([text])\n",
    "    \"\"\"\n",
    "    import hashlib\n",
    "    import random\n",
    "\n",
    "    # Use text hash as seed for reproducible \"embeddings\"\n",
    "    seed = int(hashlib.md5(text.encode()).hexdigest(), 16) % (2**32)\n",
    "    random.seed(seed)\n",
    "\n",
    "    return [random.gauss(0, 1) for _ in range(dimensions)]\n",
    "\n",
    "# Example documents to embed\n",
    "articles = [\n",
    "    {\n",
    "        'title': 'Introduction to Python',\n",
    "        'content': 'Python is a high-level programming language known for its simplicity and readability.'\n",
    "    },\n",
    "    {\n",
    "        'title': 'JavaScript Basics',\n",
    "        'content': 'JavaScript is the programming language of the web, enabling interactive websites.'\n",
    "    },\n",
    "    {\n",
    "        'title': 'Database Design Principles',\n",
    "        'content': 'Good database design ensures data integrity, reduces redundancy, and improves query performance.'\n",
    "    }\n",
    "]\n",
    "\n",
    "# Store articles with embeddings\n",
    "for i, article in enumerate(articles):\n",
    "    doc = documents.new()\n",
    "    doc.title = article['title']\n",
    "    doc.content = article['content']\n",
    "\n",
    "    # Generate embedding from content\n",
    "    embedding = generate_fake_embedding(article['content'])\n",
    "    doc.embedding = Vector(embedding)\n",
    "\n",
    "    doc.save(doc_id=f'article_{i}')\n",
    "    dimension_count = len(doc.embedding.to_map_value()['value'])\n",
    "    print(f\"✓ Saved: {article['title']} ({dimension_count}D)\")\n",
    "\n",
    "print(\"\\n✓ All articles embedded and stored\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 7: Vector Similarity Search with find_nearest\n",
    "\n",
    "Use FireProx's `find_nearest()` method to perform vector similarity search and find nearest neighbors.\n",
    "\n",
    "**Requirements**:\n",
    "- A vector index must be created on the field (using gcloud CLI or Firebase console)\n",
    "- Does NOT work with emulator (production only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a query vector (in practice, this would be an embedding of a search query)\n",
    "query_text = \"programming languages and coding\"\n",
    "query_embedding = generate_fake_embedding(query_text)\n",
    "query_vector = Vector(query_embedding)\n",
    "\n",
    "print(f\"Searching for documents similar to: '{query_text}'\")\n",
    "print(\"\\nNote: This requires a vector index on the 'embedding' field.\")\n",
    "print(\"Create index with: gcloud firestore indexes composite create ...\\n\")\n",
    "\n",
    "# Find nearest neighbors using EUCLIDEAN distance\n",
    "try:\n",
    "    vector_query = documents.find_nearest(\n",
    "        vector_field=\"embedding\",\n",
    "        query_vector=query_vector,\n",
    "        distance_measure=DistanceMeasure.EUCLIDEAN,\n",
    "        limit=5,\n",
    "        distance_result_field=\"distance\"  # Optional: store calculated distance\n",
    "    )\n",
    "\n",
    "    print(\"Top 5 nearest neighbors:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for doc in vector_query.get():\n",
    "        print(f\"\\nTitle: {doc.title}\")\n",
    "        print(f\"Content: {doc.content}\")\n",
    "        # Access distance if distance_result_field was specified\n",
    "        if hasattr(doc, 'distance'):\n",
    "            print(f\"Distance: {doc.distance:.4f}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"⚠️  Vector search failed: {e}\")\n",
    "    print(\"\\nThis is expected if:\")\n",
    "    print(\"  1. No vector index exists on the 'embedding' field\")\n",
    "    print(\"  2. Running against emulator (vectors not supported)\")\n",
    "    print(\"  3. Collection has no documents with embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 8: Vector Search with Pre-filtering\n",
    "\n",
    "Combine `where()` clauses with `find_nearest()` to filter documents before searching.\n",
    "\n",
    "**Note**: Requires a composite index when combining filters with vector search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's add a category field to our documents\n",
    "doc_python = db.doc('semantic_documents/article_0')\n",
    "doc_python.fetch()\n",
    "doc_python.category = 'programming'\n",
    "doc_python.save()\n",
    "\n",
    "doc_js = db.doc('semantic_documents/article_1')\n",
    "doc_js.fetch()\n",
    "doc_js.category = 'programming'\n",
    "doc_js.save()\n",
    "\n",
    "doc_db = db.doc('semantic_documents/article_2')\n",
    "doc_db.fetch()\n",
    "doc_db.category = 'database'\n",
    "doc_db.save()\n",
    "\n",
    "print(\"✓ Added categories to documents\")\n",
    "\n",
    "# Now search with pre-filtering\n",
    "try:\n",
    "    # Find nearest neighbors only among 'programming' category\n",
    "    filtered_query = (\n",
    "        documents\n",
    "        .where('category', '==', 'programming')\n",
    "        .find_nearest(\n",
    "            vector_field=\"embedding\",\n",
    "            query_vector=query_vector,\n",
    "            distance_measure=DistanceMeasure.COSINE,\n",
    "            limit=3\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    print(\"\\nFiltered results (category='programming' only):\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for doc in filtered_query.get():\n",
    "        print(f\"\\nTitle: {doc.title}\")\n",
    "        print(f\"Category: {doc.category}\")\n",
    "        print(f\"Content: {doc.content[:50]}...\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\n⚠️  Filtered vector search failed: {e}\")\n",
    "    print(\"\\nThis requires a composite index with:\")\n",
    "    print(\"  - category field\")\n",
    "    print(\"  - embedding vector field\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 9: Async Vector Search\n",
    "\n",
    "Vector search works with the async API as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Async vector search\n",
    "async_documents = async_db.collection('semantic_documents')\n",
    "\n",
    "try:\n",
    "    async_vector_query = async_documents.find_nearest(\n",
    "        vector_field=\"embedding\",\n",
    "        query_vector=query_vector,\n",
    "        distance_measure=DistanceMeasure.DOT_PRODUCT,\n",
    "        limit=3\n",
    "    )\n",
    "\n",
    "    print(\"Async vector search results:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    async for doc in async_vector_query.stream():\n",
    "        print(f\"\\nTitle: {doc.title}\")\n",
    "        print(f\"Content: {doc.content[:60]}...\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"⚠️  Async vector search failed: {e}\")\n",
    "    print(\"Requires vector index and production Firestore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance Measures\n",
    "\n",
    "Firestore supports three distance measures for vector similarity:\n",
    "\n",
    "1. **EUCLIDEAN**: Measures straight-line distance between vectors\n",
    "   - Good for: Spatial data, when magnitude matters\n",
    "   - Range: 0 to ∞ (lower is more similar)\n",
    "\n",
    "2. **COSINE**: Measures angle between vectors (direction)\n",
    "   - Good for: Text embeddings, when direction matters more than magnitude\n",
    "   - Range: -1 to 1 (higher is more similar)\n",
    "\n",
    "3. **DOT_PRODUCT**: Measures both angle and magnitude\n",
    "   - Good for: When both direction and magnitude are important\n",
    "   - Range: -∞ to ∞ (higher is more similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different distance measures\n",
    "print(\"Comparing distance measures:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for measure in [DistanceMeasure.EUCLIDEAN, DistanceMeasure.COSINE, DistanceMeasure.DOT_PRODUCT]:\n",
    "    print(f\"\\n{measure.name}:\")\n",
    "    try:\n",
    "        query = documents.find_nearest(\n",
    "            vector_field=\"embedding\",\n",
    "            query_vector=query_vector,\n",
    "            distance_measure=measure,\n",
    "            limit=2,\n",
    "            distance_result_field=\"distance\"\n",
    "        )\n",
    "        \n",
    "        for doc in query.get():\n",
    "            distance = getattr(doc, 'distance', 'N/A')\n",
    "            print(f\"  - {doc.title}: {distance}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  ⚠️  Failed: {str(e)[:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Server-Side Embedding Generation\n",
    "\n",
    "### Firebase Extension for Automatic Embeddings\n",
    "\n",
    "Firebase provides extensions that can automatically generate embeddings when documents are created or updated:\n",
    "\n",
    "**How it works**:\n",
    "1. Configure which collection and field to monitor\n",
    "2. When a document is created/updated, the extension triggers\n",
    "3. It sends the text field to an embedding model (Vertex AI / Gemini)\n",
    "4. The generated embedding is stored back in the document\n",
    "\n",
    "**Example workflow**:\n",
    "```python\n",
    "# 1. Save document with text content (no embedding yet)\n",
    "doc = documents.new()\n",
    "doc.title = \"My Article\"\n",
    "doc.content = \"This is the text content to embed...\"\n",
    "doc.save()\n",
    "\n",
    "# 2. Extension automatically triggers:\n",
    "#    - Reads doc.content\n",
    "#    - Calls Vertex AI embedding API\n",
    "#    - Writes result to doc.embedding\n",
    "\n",
    "# 3. Read back with embedding (after extension completes)\n",
    "import time\n",
    "time.sleep(2)  # Wait for extension to process\n",
    "doc.fetch(force=True)\n",
    "print(f\"Auto-generated embedding: {len(doc.embedding.to_map_value()['value'])}D\")\n",
    "```\n",
    "\n",
    "**Alternative: Client-Side Embeddings**\n",
    "\n",
    "For more control, generate embeddings in your application:\n",
    "\n",
    "```python\n",
    "# Using OpenAI\n",
    "import openai\n",
    "\n",
    "response = openai.embeddings.create(\n",
    "    input=\"Your text here\",\n",
    "    model=\"text-embedding-ada-002\"\n",
    ")\n",
    "embedding = response.data[0].embedding\n",
    "doc.embedding = Vector(embedding)\n",
    "doc.save()\n",
    "\n",
    "# Using Sentence Transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embedding = model.encode(\"Your text here\").tolist()\n",
    "doc.embedding = Vector(embedding)\n",
    "doc.save()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete test documents\n",
    "test_docs = [\n",
    "    'ml_intro',\n",
    "    'dl_fundamentals',\n",
    "    'nn_architectures',\n",
    "    'article_0',\n",
    "    'article_1',\n",
    "    'article_2'\n",
    "]\n",
    "\n",
    "for doc_id in test_docs:\n",
    "    try:\n",
    "        doc = db.doc(f'semantic_documents/{doc_id}')\n",
    "        doc.delete()\n",
    "        print(f\"✓ Deleted {doc_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  (Could not delete {doc_id}: {e})\")\n",
    "\n",
    "print(\"\\n✓ Cleanup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Native Vector Support**: FireProx uses native `google.cloud.firestore_v1.vector.Vector` directly\n",
    "2. **Automatic Handling**: FireProx preserves Vector types seamlessly during read/write operations\n",
    "3. **Vector Search**: Use `find_nearest()` for similarity search and nearest neighbor queries\n",
    "4. **Distance Measures**: Choose from EUCLIDEAN, COSINE, or DOT_PRODUCT based on your use case\n",
    "5. **Pre-filtering**: Combine `where()` with `find_nearest()` for filtered vector search\n",
    "6. **Sync & Async**: Works with both synchronous and asynchronous APIs\n",
    "7. **Production Only**: Vectors do NOT work with Firestore emulator\n",
    "\n",
    "### Limitations to Remember\n",
    "\n",
    "- ⚠️ Emulator does not support vectors\n",
    "- ⚠️ Maximum 2048 dimensions\n",
    "- ⚠️ Maximum 1000 results per query\n",
    "- ⚠️ Vectors cannot be nested in arrays/maps\n",
    "- ⚠️ Vectors must be top-level document fields\n",
    "- ⚠️ Requires vector index for search operations\n",
    "- ⚠️ No real-time snapshot listeners for vector queries\n",
    "\n",
    "### Use Cases\n",
    "\n",
    "- **Semantic Search**: Find documents similar to a query\n",
    "- **Content Recommendations**: Suggest related articles/products\n",
    "- **Question Answering**: Match questions to relevant answers\n",
    "- **Image Search**: Find similar images by embedding\n",
    "- **Clustering**: Group similar documents together\n",
    "- **Duplicate Detection**: Find near-duplicate content\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "To build a complete semantic search system:\n",
    "1. Choose an embedding model (OpenAI, Sentence Transformers, Vertex AI)\n",
    "2. Generate embeddings for your documents\n",
    "3. Store using native `Vector` type\n",
    "4. Create vector indexes (using gcloud CLI or Firebase console)\n",
    "5. Use `find_nearest()` for similarity search\n",
    "6. Optionally combine with filters using `where()`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
